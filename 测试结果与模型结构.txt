==================================================
开始批量测试...
总共读取了 8716 个测试用例
开始批量生成答案...
已测试 100 个用例，当前成功率: 100.00%
已测试 200 个用例，当前成功率: 100.00%
已测试 300 个用例，当前成功率: 100.00%
已测试 400 个用例，当前成功率: 100.00%

已测试 8300 个用例，当前成功率: 100.00%
已测试 8400 个用例，当前成功率: 100.00%
已测试 8500 个用例，当前成功率: 100.00%
已测试 8600 个用例，当前成功率: 99.99%
已测试 8700 个用例，当前成功率: 99.99%

=== 测试结果 ===
总测试用例数: 8716
正确用例数: 8715
成功率: 99.99%

全部失败的用例:
1. 输入: 1 2 8 10
   期望: 2 8 1 - * 10 + (结果: 24.0)
   生成: 8 2 1 10 - * - (结果: 26.0)



T5ForConditionalGeneration(
  (shared): Embedding(32128, 384)
  (encoder): T5Stack(
    (embed_tokens): Embedding(32128, 384)
    (block): ModuleList(
      (0): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): Linear(in_features=384, out_features=512, bias=False)
              (k): Linear(in_features=384, out_features=512, bias=False)
              (v): Linear(in_features=384, out_features=512, bias=False)
              (o): Linear(in_features=512, out_features=384, bias=False)
              (relative_attention_bias): Embedding(32, 8)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseActDense(
              (wi): Linear(in_features=384, out_features=1536, bias=False)
              (wo): Linear(in_features=1536, out_features=384, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
              (act): ReLU()
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (1-3): 3 x T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): Linear(in_features=384, out_features=512, bias=False)
              (k): Linear(in_features=384, out_features=512, bias=False)
              (v): Linear(in_features=384, out_features=512, bias=False)
              (o): Linear(in_features=512, out_features=384, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerFF(
            (DenseReluDense): T5DenseActDense(
              (wi): Linear(in_features=384, out_features=1536, bias=False)
              (wo): Linear(in_features=1536, out_features=384, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
              (act): ReLU()
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (final_layer_norm): T5LayerNorm()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (decoder): T5Stack(
    (embed_tokens): Embedding(32128, 384)
    (block): ModuleList(
      (0): T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): Linear(in_features=384, out_features=512, bias=False)
              (k): Linear(in_features=384, out_features=512, bias=False)
              (v): Linear(in_features=384, out_features=512, bias=False)
              (o): Linear(in_features=512, out_features=384, bias=False)
              (relative_attention_bias): Embedding(32, 8)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=384, out_features=512, bias=False)
              (k): Linear(in_features=384, out_features=512, bias=False)
              (v): Linear(in_features=384, out_features=512, bias=False)
              (o): Linear(in_features=512, out_features=384, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseActDense(
              (wi): Linear(in_features=384, out_features=1536, bias=False)
              (wo): Linear(in_features=1536, out_features=384, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
              (act): ReLU()
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (1-3): 3 x T5Block(
        (layer): ModuleList(
          (0): T5LayerSelfAttention(
            (SelfAttention): T5Attention(
              (q): Linear(in_features=384, out_features=512, bias=False)
              (k): Linear(in_features=384, out_features=512, bias=False)
              (v): Linear(in_features=384, out_features=512, bias=False)
              (o): Linear(in_features=512, out_features=384, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): T5LayerCrossAttention(
            (EncDecAttention): T5Attention(
              (q): Linear(in_features=384, out_features=512, bias=False)
              (k): Linear(in_features=384, out_features=512, bias=False)
              (v): Linear(in_features=384, out_features=512, bias=False)
              (o): Linear(in_features=512, out_features=384, bias=False)
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): T5LayerFF(
            (DenseReluDense): T5DenseActDense(
              (wi): Linear(in_features=384, out_features=1536, bias=False)
              (wo): Linear(in_features=1536, out_features=384, bias=False)
              (dropout): Dropout(p=0.1, inplace=False)
              (act): ReLU()
            )
            (layer_norm): T5LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (final_layer_norm): T5LayerNorm()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (lm_head): Linear(in_features=384, out_features=32128, bias=False)
)
